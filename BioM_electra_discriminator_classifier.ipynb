{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m4dgy5ld34R",
        "outputId": "ab36722a-cd3d-4834-a894-7806e4060845"
      },
      "id": "-m4dgy5ld34R",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 14.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 51.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 53.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 65.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install sentencepiece"
      ],
      "metadata": {
        "id": "Exwfw7t6c-Ei"
      },
      "id": "Exwfw7t6c-Ei",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4a537e5e",
      "metadata": {
        "id": "4a537e5e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "pt7S0klmd8X5",
        "outputId": "529e7386-38c6-46e0-e7f5-36c6baa86cf6"
      },
      "id": "pt7S0klmd8X5",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3138e84d-283f-459d-8fa6-8fd15622cf04\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3138e84d-283f-459d-8fa6-8fd15622cf04\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving spam_data.csv to spam_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7767d2f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7767d2f6",
        "outputId": "95d0f92a-c825-420b-e005-cf17f3692086"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-916b1f65-393f-4de4-95d3-16de66a4aa68\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-916b1f65-393f-4de4-95d3-16de66a4aa68')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-916b1f65-393f-4de4-95d3-16de66a4aa68 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-916b1f65-393f-4de4-95d3-16de66a4aa68');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Category                                            Message\n",
              "0         ham  Go until jurong point, crazy.. Available only ...\n",
              "1         ham                      Ok lar... Joking wif u oni...\n",
              "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3         ham  U dun say so early hor... U c already then say...\n",
              "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...       ...                                                ...\n",
              "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568      ham               Will ü b going to esplanade fr home?\n",
              "5569      ham  Pity, * was in mood for that. So...any other s...\n",
              "5570      ham  The guy did some bitching but I acted like i'd...\n",
              "5571      ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import io\n",
        "data = pd.read_csv(io.BytesIO(uploaded['spam_data.csv']))\n",
        "data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4f9d5894",
      "metadata": {
        "id": "4f9d5894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "ffe97717332a4761b9b5f720106b6771",
            "f2888043e5d94db8822a62adaafcab32",
            "6aec31147a864be9a24abdb9a46692e7",
            "4ca63e30ee01445e85f808573d6e5a55",
            "6c675789a4444a8fa2b5160d3e4322e2",
            "33217b4b0a1b426cbe44c2e15880d791",
            "3a27aa3fcfcb4908808cec9af519732a",
            "35ca3f2e3abf41fda4921aea20a9e90d",
            "e6113ca64f1e463283f3fda3a56b1572",
            "8694e51ab8964517b6423bf523e8297b",
            "fd41df21e20f4eaaa12bee81c3b12d92",
            "fe826358e01d4fd8b97b577464b87c2d",
            "e937a9233b794b69bbe320d8f125f5d8",
            "c2a02bd28acd440c90a576850940d355",
            "af852eb934ca4684a27d36660b53b8d7",
            "0b7c09cec7f14b988d346e6137945b0b",
            "05bb6fb47d8c4cd4a7b19cd2379043ac",
            "2a4ee5328eb24fda85736bd009c6729b",
            "3fe19de71ec44e4c986614dabb773f9d",
            "f14048b137bf4b6d8430a95544d19fee",
            "024ebd9cddd84ca7a5f648a0bd16c021",
            "a4119018af8e404093c9cbede462fc4e",
            "b4181aaf5b2f49d9a1d9b4ac9da8d6c1",
            "f9fa3d70253e4ff181e901f71378e7e1",
            "940afa10b5ae4ee1a80524e01e606379",
            "bb6281863c6344feaf4021628de95b98",
            "269d97384a504ce6aa846fb0f4dce566",
            "b302991ef6c248d584cbfc83ea034c9f",
            "61588667c66045d88a64e149daa02eea",
            "4ad753575b4142c4b6e8fe879ed6ab75",
            "2b4bdd3c4bb24d1c8d95173d142fc55b",
            "88407d80a87443eeb29e2bcc1747ddcb",
            "de249909d3de490ea1c1d9357157bac3"
          ]
        },
        "outputId": "1847355f-7d5a-45f8-f155-17f27e99c317"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffe97717332a4761b9b5f720106b6771",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe826358e01d4fd8b97b577464b87c2d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/220k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4181aaf5b2f49d9a1d9b4ac9da8d6c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/413M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#sultan/BioM-ELECTRA-Base-Discriminator\n",
        "#does not require taking mean from the output\n",
        "#output is token for each word\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForPreTraining\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sultan/BioM-ELECTRA-Base-Discriminator\")\n",
        "\n",
        "model = AutoModelForPreTraining.from_pretrained(\"sultan/BioM-ELECTRA-Base-Discriminator\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "3c19e15f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c19e15f",
        "outputId": "1c3386a5-b3eb-4217-a9e7-e66b667881b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "TOKENS.............\n",
            "[['i', 'will', 'wat', '##ch', 'mov', '##ie', 'ton', '##ight'], ['hi', 'i', 'am', 'fine']]\n",
            "\n",
            "\n",
            "TOKEN ENCODER...............\n",
            "{'input_ids': tensor([[    2,    50,  2982,  8713,  1831,  9282,  3248, 15045,  2001,     3,\n",
            "             0,     0,     0,     0,     0],\n",
            "        [    2, 11245,    50,  1925,  8053,     3,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ],
      "source": [
        "example_input = [\"I will watch movie tonight\",\"Hi I am fine\"]\n",
        "print(\"\\n\")\n",
        "print(\"TOKENS.............\")\n",
        "print([tokenizer.tokenize(i) for i in example_input]) \n",
        "print(\"\\n\")\n",
        "print(\"TOKEN ENCODER...............\")\n",
        "example_output = tokenizer(example_input,padding='max_length', max_length = 15, \n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "print(example_output) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "703bde18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "703bde18",
        "outputId": "bd111831-2de5-4c2a-e3f7-3705fd99e46b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 15])\n",
            "torch.Size([2, 15])\n",
            "torch.Size([2, 15])\n"
          ]
        }
      ],
      "source": [
        "print(example_output[\"input_ids\"].shape)\n",
        "print(example_output[\"token_type_ids\"].shape)\n",
        "print(example_output[\"attention_mask\"].shape) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "f8cb9257",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8cb9257",
        "outputId": "30b3f217-aff5-4332-c8ef-d9e638adbc9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ElectraForPreTrainingOutput(loss=None, logits=tensor([[-7.7169, -3.3260, -3.5448, -8.1897, -7.8256, -7.4773, -6.8825, -2.1196,\n",
            "         -1.2574, -7.7169, -0.9727, -0.1492, -0.1814, -0.0261, -0.0497],\n",
            "        [-5.6776,  0.8574, -2.6181, -3.2283, -2.8699, -5.6776, -2.1290, -1.9455,\n",
            "         -1.9007, -1.9670, -1.8714, -1.8152, -1.7978, -1.8397, -1.8363]],\n",
            "       grad_fn=<SqueezeBackward1>), hidden_states=None, attentions=None)\n"
          ]
        }
      ],
      "source": [
        "out = model(example_output[\"input_ids\"],example_output[\"attention_mask\"])\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "28232a8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28232a8e",
        "outputId": "8c4c9ade-12b6-494d-fb81-2cf126d97b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 15])\n"
          ]
        }
      ],
      "source": [
        "print(out[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specify the below paramaters based on the output from the transformer model"
      ],
      "metadata": {
        "id": "VHIYzxuvqz_j"
      },
      "id": "VHIYzxuvqz_j"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#whether you need to take the mean of the output or not- depends upon the transformer model output\n",
        "take_mean = False \n",
        "#which output are you taking from all the outputs you got from the transformer model- if it is the fisrt output keep this as 0 itslef\n",
        "return_index = 0\n",
        "#maximum length of the output sequence\n",
        "maxlen = 256\n",
        "#output dimension to be returned from the transformer model\n",
        "output_dim = maxlen\n",
        "#batch size\n",
        "bs = 4\n",
        "#number of classes\n",
        "classes = 2\n",
        "#label dictionary\n",
        "labels = {\"spam\":0,\"ham\":1}\n",
        "label_column_name = \"Category\"\n",
        "text_column_name = \"Message\""
      ],
      "metadata": {
        "id": "YPLnAODio5oI"
      },
      "id": "YPLnAODio5oI",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bd6498ff",
      "metadata": {
        "id": "bd6498ff"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "3bae7da6",
      "metadata": {
        "id": "3bae7da6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "22d7e48f",
      "metadata": {
        "id": "22d7e48f"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self,df):\n",
        "        self.labels = [labels[label] for label in df[label_column_name]]\n",
        "        self.texts = [tokenizer(text, padding='max_length', max_length = maxlen, truncation=True, return_tensors=\"pt\") \n",
        "                      for text in df[text_column_name]]\n",
        "        \n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "        \n",
        "    def get_batch_labels(self,idx):\n",
        "        return self.labels[idx] \n",
        "        \n",
        "    def get_batch_text(self,idx):\n",
        "        return self.texts[idx]\n",
        "        \n",
        "    def __getitem__(self,idx):\n",
        "        batch_x = self.get_batch_text(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "        return batch_x,batch_y\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "504c3ffa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "504c3ffa",
        "outputId": "431c0103-a82f-4c7f-f213-c9dad5cab55c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4457, 2) (557, 2) (558, 2)\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "df_train, df_val, df_test = np.split(data.sample(frac=1, random_state=42), \n",
        "                                     [int(.8*len(data)), int(.9*len(data))])\n",
        "print(df_train.shape, df_val.shape, df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34c715d5",
      "metadata": {
        "id": "34c715d5"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "916cfbe6",
      "metadata": {
        "id": "916cfbe6"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, tf_model,output_dim,dropout=0.5):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.bert = tf_model\n",
        "        self.dropout = nn.Dropout(dropout) \n",
        "        self.linear = nn.Linear(output_dim,classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self,input_id, mask,return_mean):\n",
        "        pooled_out = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)[return_index]\n",
        "        if return_mean:\n",
        "          pooled_out = torch.mean(pooled_out,1)\n",
        "        out = self.dropout(pooled_out)\n",
        "        \n",
        "        out = self.linear(out)\n",
        "        out = self.relu(out)\n",
        "        \n",
        "        return out\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e7baa5b",
      "metadata": {
        "id": "1e7baa5b"
      },
      "source": [
        "# Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "4a25ade3",
      "metadata": {
        "id": "4a25ade3"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "0db9db82",
      "metadata": {
        "id": "0db9db82"
      },
      "outputs": [],
      "source": [
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "    train1,val1 = Dataset(train_data), Dataset(val_data)\n",
        "    \n",
        "    train_dataloader = torch.utils.data.DataLoader(train1, batch_size=bs, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val1, batch_size=bs, shuffle=True)\n",
        "    \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "    \n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        total_train_acc = 0\n",
        "        total_train_loss = 0\n",
        "        \n",
        "        for text,label in tqdm(train_dataloader):\n",
        "            label = label.to(device)          \n",
        "            \n",
        "            input_id = torch.squeeze(text[\"input_ids\"], 1)\n",
        "            mask = torch.squeeze(text[\"attention_mask\"],1)\n",
        "            input_id = input_id.to(device)\n",
        "            mask = mask.to(device)\n",
        "                    \n",
        "            output = model(input_id,mask,return_mean = take_mean)\n",
        "            # print(output.shape)\n",
        "#             print(label.shape)\n",
        "            batch_loss = criterion(output, label)\n",
        "            total_train_loss+=batch_loss.item()\n",
        "            acc= (output.argmax(dim=1)==label).sum().item()\n",
        "            total_train_acc+=acc\n",
        "            \n",
        "            model.zero_grad()\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        total_val_acc = 0\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for val_text,val_label in tqdm(val_dataloader):\n",
        "                val_label = val_label.to(device)\n",
        "                input_id = torch.squeeze(val_text[\"input_ids\"], 1)\n",
        "                mask = torch.squeeze(val_text[\"attention_mask\"],1)\n",
        "\n",
        "                input_id = input_id.to(device)\n",
        "                mask = mask.to(device)\n",
        "                output = model(input_id,mask,return_mean = take_mean)\n",
        "                batch_loss = criterion(output, val_label)\n",
        "                total_val_loss+=batch_loss.item()\n",
        "                acc= (output.argmax(dim=1)==val_label).sum().item()\n",
        "                total_val_acc+=acc\n",
        "            \n",
        "        print(\n",
        "                f'Epochs: {epoch + 1} | Train Loss: {total_train_loss / len(train_data): .3f} | Train Accuracy: {total_train_acc / len(train_data): .3f} | Val Loss: {total_val_loss / len(val_data): .3f} | Val Accuracy: {total_val_acc / len(val_data): .3f}')\n",
        "                  \n",
        "        \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "adfe91ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adfe91ba",
        "outputId": "9a3483ba-7d5f-443d-f294-7365511f9b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/140 [00:02<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2])\n",
            "tensor(0.6543, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train1,val1 = Dataset(df_train), Dataset(df_val)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "val_dataloader = torch.utils.data.DataLoader(val1, batch_size=bs, shuffle=True)\n",
        "for val_text,val_label in tqdm(val_dataloader):\n",
        "                \n",
        "        input_id = torch.squeeze(val_text[\"input_ids\"], 1)\n",
        "        mask = torch.squeeze(val_text[\"attention_mask\"],1)\n",
        "        pooled_out = model(input_ids= input_id, attention_mask=mask,return_dict=False)[return_index]\n",
        "        if take_mean:\n",
        "          pooled_out = torch.mean(pooled_out,1)\n",
        "        out = nn.Dropout(0.2)(pooled_out)\n",
        "        out = nn.Linear(output_dim,classes)(out)\n",
        "        out = nn.ReLU()(out)\n",
        "        print(out.shape)\n",
        "        batch_loss = criterion(out, val_label)\n",
        "        print(batch_loss)\n",
        "        break "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "f853340a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "f853340a",
        "outputId": "ec1a13c0-2fbc-4608-c765-1bd8b9030835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 11/1115 [00:02<04:13,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-0a5c5ed03a0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-89ae6d8af673>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mtotal_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "EPOCHS = 1\n",
        "model1 = Classifier(model,output_dim)\n",
        "LR = 1e-6\n",
        "train(model1, df_train, df_val, LR, EPOCHS)  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KFold Cross validation"
      ],
      "metadata": {
        "id": "EWoRBytpZd97"
      },
      "id": "EWoRBytpZd97"
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_splits = 5"
      ],
      "metadata": {
        "id": "wBVOGZK-xiFG"
      },
      "id": "wBVOGZK-xiFG",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def train_cv(model, data, learning_rate, epochs):\n",
        "    splits= KFold(n_splits = no_of_splits, shuffle=True)\n",
        "    best_acc = 0.0\n",
        "    for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(data)))): \n",
        "      print('------------fold no---------{}----------------------'.format(fold))\n",
        "      train1 = Dataset(data.iloc[train_idx])\n",
        "      val1 = Dataset(data.iloc[val_idx])\n",
        "      train_dataloader = torch.utils.data.DataLoader(train1, batch_size=bs, shuffle=True)\n",
        "      val_dataloader = torch.utils.data.DataLoader(val1, batch_size=bs, shuffle=True)\n",
        "    \n",
        "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "      \n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "      optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "      \n",
        "      model = model.to(device)\n",
        "      criterion = criterion.to(device)\n",
        "\n",
        "    \n",
        "      for epoch in range(epochs):\n",
        "          total_train_acc = 0\n",
        "          total_train_loss = 0\n",
        "          \n",
        "          for text,label in tqdm(train_dataloader):\n",
        "              label = label.to(device)          \n",
        "              \n",
        "              input_id = torch.squeeze(text[\"input_ids\"], 1)\n",
        "              mask = torch.squeeze(text[\"attention_mask\"],1)\n",
        "              input_id = input_id.to(device)\n",
        "              mask = mask.to(device)\n",
        "                      \n",
        "              output = model(input_id,mask,return_mean= take_mean)\n",
        "              # print(output.shape)\n",
        "  #             print(label.shape)\n",
        "              batch_loss = criterion(output, label)\n",
        "              total_train_loss+=batch_loss.item()\n",
        "              acc= (output.argmax(dim=1)==label).sum().item()\n",
        "              total_train_acc+=acc\n",
        "              \n",
        "              model.zero_grad()\n",
        "              batch_loss.backward()\n",
        "              optimizer.step()\n",
        "              \n",
        "          total_val_acc = 0\n",
        "          total_val_loss = 0\n",
        "          with torch.no_grad():\n",
        "              for val_text,val_label in tqdm(val_dataloader):\n",
        "                  val_label = val_label.to(device)\n",
        "                  input_id = torch.squeeze(val_text[\"input_ids\"], 1)\n",
        "                  mask = torch.squeeze(val_text[\"attention_mask\"],1)\n",
        "\n",
        "                  input_id = input_id.to(device)\n",
        "                  mask = mask.to(device)\n",
        "                  output = model(input_id,mask, return_mean= take_mean)\n",
        "                  batch_loss = criterion(output, val_label)\n",
        "                  total_val_loss+=batch_loss.item()\n",
        "                  acc= (output.argmax(dim=1)==val_label).sum().item()\n",
        "                  total_val_acc+=acc\n",
        "              \n",
        "          print(\n",
        "                  f'Epochs: {epoch + 1} | Train Loss: {total_train_loss / len(train_idx): .3f} | Train Accuracy: {total_train_acc / len(train_idx): .3f} | Val Loss: {total_val_loss / len(val_idx): .3f} | Val Accuracy: {total_val_acc / len(val_idx): .3f}')\n",
        "                  \n",
        "      if total_val_acc/len(val_idx)>best_acc:\n",
        "        best_acc = total_val_acc/len(val_idx)\n",
        "        print(\"The best accuracy is--->\", best_acc)\n",
        "      else:\n",
        "        print(\"accuracy has not improved from the previous fold\")\n",
        "      print(\".........................................................................................................\")\n",
        "\n",
        "            "
      ],
      "metadata": {
        "id": "SYUUAJICNqD_"
      },
      "id": "SYUUAJICNqD_",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1\n",
        "model1 = Classifier(model,output_dim)\n",
        "LR = 1e-6\n",
        "train_cv(model1, data, LR, EPOCHS) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "gjGJ8_hPQyeJ",
        "outputId": "13041efc-92a8-407f-c5f5-7fa3579aae69"
      },
      "id": "gjGJ8_hPQyeJ",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------fold no---------0----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 11/1115 [00:02<03:43,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-530bf9a82a91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-eaa39845aa33>\u001b[0m in \u001b[0;36mtrain_cv\u001b[0;34m(model, data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;31m#             print(label.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m               \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m               \u001b[0mtotal_train_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m               \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m               \u001b[0mtotal_train_acc\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "030c6c6b",
      "metadata": {
        "id": "030c6c6b"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=bs)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].squeeze(1).to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask,return_mean = take_mean)\n",
        "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "              total_acc_test += acc\n",
        "    \n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "a5b6052c",
      "metadata": {
        "id": "a5b6052c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac38481-98eb-406d-8908-55e6539b8b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.606\n"
          ]
        }
      ],
      "source": [
        "evaluate(model1, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11dc6c35",
      "metadata": {
        "id": "11dc6c35"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29f0fbb5",
      "metadata": {
        "id": "29f0fbb5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5ccafde",
      "metadata": {
        "id": "f5ccafde"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c418dd8",
      "metadata": {
        "id": "5c418dd8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c7f8c00",
      "metadata": {
        "id": "9c7f8c00"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2b1abfd",
      "metadata": {
        "id": "e2b1abfd"
      },
      "source": [
        "# Misc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc34731f",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "064f8e5d4da6496d85aff13889acaf93",
            "c4fcf54e1f4a484289e9c7148dc671b5",
            "d42e82002a6045dea6b9a30fe6e51368"
          ]
        },
        "id": "fc34731f",
        "outputId": "462e27f7-73b0-46ff-ad5e-fa866f37618c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "064f8e5d4da6496d85aff13889acaf93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4fcf54e1f4a484289e9c7148dc671b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d42e82002a6045dea6b9a30fe6e51368",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  101,   146,  1209,  2824,  2508, 26173,  3568,   102,     0,     0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "example_text = 'I will watch Memento tonight'\n",
        "bert_input = tokenizer(example_text,padding='max_length', max_length = 10, \n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "print(bert_input['input_ids'])\n",
        "print(bert_input['token_type_ids'])\n",
        "print(bert_input['attention_mask'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74205180",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "db3aa9ec078d4d0a8ce1f46b1662d572",
            "fab3bfbcaa964cdbbccd5100698651b3"
          ]
        },
        "id": "74205180",
        "outputId": "d5d7b930-7148-48e3-8dae-b3ab0462e571"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db3aa9ec078d4d0a8ce1f46b1662d572",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fab3bfbcaa964cdbbccd5100698651b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel\n",
        "bert = BertModel.from_pretrained('bert-base-cased')\n",
        "o=bert(bert_input[\"input_ids\"],bert_input[\"attention_mask\"],return_dict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a6197b3",
      "metadata": {
        "id": "1a6197b3",
        "outputId": "69e02d2a-233c-4b9b-b03e-71bba58d9d58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 768])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 3.5039e-01, -1.9487e-01,  1.0387e-01,  1.7135e-01,  3.0013e-01,\n",
              "          9.3626e-02,  1.7778e-01,  7.3870e-02,  1.4471e-01, -5.8956e-02,\n",
              "         -1.6891e-01,  2.9234e-01, -3.1623e-01,  3.6891e-01, -2.5948e-01,\n",
              "         -1.1955e-01, -1.8508e-02, -8.9950e-02,  2.9625e-02, -2.0191e-01,\n",
              "         -5.4164e-02,  6.2005e-02, -3.1030e-01, -4.7955e-02,  2.4356e-01,\n",
              "         -2.1378e-01,  6.4915e-01,  7.0313e-01,  5.6117e-02,  1.7772e-01,\n",
              "          4.2362e-02, -7.8822e-02,  1.2682e-01, -2.8575e-03, -1.6492e-01,\n",
              "         -1.3824e-01, -1.9517e-01,  1.1798e-01, -2.6482e-01, -1.2428e-01,\n",
              "         -2.9498e-01,  4.2889e-02,  2.7335e-01, -3.6402e-01,  4.9475e-02,\n",
              "         -3.5574e-01,  1.2514e-01, -1.0856e-01, -2.2748e-01,  1.3191e-01,\n",
              "          2.8182e-01, -2.2908e-01, -1.4320e-01, -3.8938e-02,  2.4720e-01,\n",
              "         -6.9256e-02, -8.4726e-02,  2.9137e-02, -2.4527e-01,  3.3444e-01,\n",
              "         -6.1131e-02,  3.2142e-01,  2.4662e-01,  1.1562e-01, -3.6122e-01,\n",
              "          1.9660e-01,  1.3246e-01, -1.2376e-01,  2.2001e-01, -2.1350e-01,\n",
              "          1.6302e-01, -3.9840e-01, -1.9721e-03,  7.5732e-02, -8.2790e-02,\n",
              "         -3.4630e-01,  3.7540e-01, -1.0877e-01, -8.6127e-02,  2.4375e-01,\n",
              "         -4.6174e-02,  1.0515e-01, -4.7498e-01,  1.3672e-01,  9.4311e-02,\n",
              "          4.0378e-01,  5.4088e-02, -1.8844e-01, -7.4473e-03,  6.8208e-02,\n",
              "          2.4608e-02, -3.5772e-01,  1.0560e-01, -5.2151e-02, -1.3285e-01,\n",
              "          1.6573e-01, -7.2733e-02,  1.8501e-01,  5.8960e-01,  7.6266e-02,\n",
              "          7.8162e-02, -6.4312e-02,  4.0661e-02, -2.0965e-02,  1.3536e-01,\n",
              "         -4.7224e-03,  1.1413e-01, -2.7890e-01, -8.1663e-02,  5.0609e-01,\n",
              "          1.2227e-01, -1.1595e-01,  2.4115e-01, -2.2118e-01, -3.9105e-01,\n",
              "         -4.5795e-03,  2.5054e-01,  1.0421e-01,  3.2119e-01,  5.1167e-02,\n",
              "          2.0460e-01, -9.3584e-02,  4.2558e-01,  1.6690e-01,  3.3034e-01,\n",
              "          1.3744e-01, -1.2853e-01, -8.7761e-02,  1.5499e-01, -9.7320e-02,\n",
              "          6.9111e-02,  8.3344e-02,  4.5486e-02,  2.5440e-01,  1.7359e-01,\n",
              "          1.1810e-01, -2.0521e-01,  1.5695e-01, -1.1719e+00,  1.6793e-01,\n",
              "         -1.2409e-01, -4.7748e-02,  3.0371e-01, -2.6614e-02, -6.0870e-03,\n",
              "          2.0946e-01,  7.8367e-02, -3.8489e-01,  1.6514e-01,  7.9033e-02,\n",
              "         -2.6021e-01, -2.6832e-01, -1.8175e-01, -4.0539e-03,  2.8173e-02,\n",
              "         -9.6839e-02,  8.1849e-02, -9.9809e-02,  2.9545e-01,  1.4847e-02,\n",
              "         -4.5853e-01, -3.2066e-02, -1.9087e-01,  6.8623e-02, -1.8959e-01,\n",
              "         -4.9559e-02,  3.4623e-01, -1.7110e-01, -1.5416e-01,  4.5111e-01,\n",
              "          1.8348e-02, -8.5738e-02, -5.5573e-01,  6.1617e-01, -1.4691e-01,\n",
              "          4.7823e-02,  1.2227e-01,  1.8114e-01, -4.3702e-02,  1.3620e-01,\n",
              "          2.1124e-02, -6.5086e-02, -1.6934e-02, -2.9448e-01,  4.9941e-01,\n",
              "         -2.5063e-01,  2.8173e-01,  6.5202e-02, -2.5130e-01, -1.5076e-01,\n",
              "          1.2276e-01, -2.7114e-01, -7.1955e-02,  1.3095e-01, -3.7662e-01,\n",
              "         -7.6215e-02, -8.1331e-02,  7.8688e-02,  5.1641e-02,  2.0114e-01,\n",
              "         -2.3942e-01, -3.2674e-02,  3.9713e-02, -1.2278e-01, -3.3778e-02,\n",
              "          1.1674e-01, -1.5994e-01, -4.8297e-02, -2.3474e-01, -3.4547e-01,\n",
              "         -1.6946e-01, -2.1336e-01,  6.7294e-03, -1.0204e-01, -1.3007e-01,\n",
              "          1.3036e-01, -2.6697e-01, -1.5277e-01, -2.1560e-02,  1.2529e-01,\n",
              "         -1.7673e-01,  4.0461e-01,  1.1516e-01, -3.7069e-01, -1.9048e-02,\n",
              "          2.8642e-01,  2.7011e-01,  2.5728e-01,  4.9306e-01, -8.6587e-02,\n",
              "         -8.8355e-02, -1.0224e-02, -3.0829e-02, -4.2746e-01, -2.3315e-01,\n",
              "          1.1407e-01,  2.9881e-02,  2.9122e-01, -9.5693e-02,  9.6014e-02,\n",
              "          1.1207e-01, -2.5290e-01,  5.1705e-01, -2.5176e-01,  1.5353e-01,\n",
              "          3.0712e-01, -1.2038e-01,  3.9304e-01,  5.8093e-02,  3.2707e-01,\n",
              "          7.1113e-02, -6.8760e-03, -1.5939e-01,  7.3610e-02,  2.7999e-01,\n",
              "         -9.1768e-02, -1.1607e-01, -9.8572e-03, -4.0738e-01, -3.1817e-01,\n",
              "         -1.3132e-01, -3.2392e-01,  2.2314e-01,  2.1944e-01, -4.2707e-01,\n",
              "         -8.0792e-02,  3.0054e-01,  9.7882e-02, -5.8658e-01,  1.3278e-01,\n",
              "         -1.7577e-01, -5.0128e-02, -3.7557e-01,  1.1043e-01, -2.1439e-01,\n",
              "          2.1052e-01, -1.5955e-01, -1.4317e-01,  4.1672e-02, -8.8598e-02,\n",
              "          2.0533e-01,  3.1636e-01,  1.4928e-01,  4.6405e-01, -5.5639e-02,\n",
              "          3.3243e-01,  2.1570e-01, -1.4509e-02,  1.2817e-01,  2.2753e-01,\n",
              "         -2.3141e-01, -4.7498e-02, -3.2837e-01, -2.2558e-01,  4.6987e-01,\n",
              "         -1.3580e-02, -3.0807e-01,  2.5715e-01, -3.0430e-01,  5.8742e-03,\n",
              "          2.3608e-01, -8.1234e-02,  1.2594e-02,  9.9371e-02, -8.0131e-01,\n",
              "          2.0405e-02,  2.5569e-01,  4.8127e-01,  1.4594e-01,  1.7216e-01,\n",
              "          5.9461e-01, -1.0809e-01, -4.0611e-01, -2.7642e-01, -5.4247e-01,\n",
              "         -2.1794e-01, -9.9836e-02, -1.5789e-01, -1.9016e-01,  1.0710e-01,\n",
              "          9.6296e-02,  8.1896e-02, -1.0771e-01,  3.0290e-01, -1.0347e-02,\n",
              "         -7.6813e-02, -2.1284e-01, -6.5792e-02,  2.4200e-02, -2.7309e-01,\n",
              "          7.5905e-02,  7.3333e-03, -1.0625e-01, -2.4093e-01, -2.4690e-01,\n",
              "          1.0411e-01, -2.7970e-01,  3.3338e-01, -1.6579e-01,  3.3535e-02,\n",
              "          2.1336e-01,  2.7398e-01,  3.1726e-01, -2.6805e-01, -8.6553e-02,\n",
              "          1.4341e-01,  1.0297e-01,  2.1317e-01, -2.0062e-01,  5.0855e-02,\n",
              "         -1.4542e-01, -6.7139e-02, -4.5295e-01, -1.1972e-01,  3.8135e-01,\n",
              "          4.6307e-02, -3.2958e-01, -2.7021e-01,  1.7337e-01,  2.0223e-01,\n",
              "          5.2590e-02, -3.1558e-01,  2.3644e-01,  9.6987e-02, -2.0466e-01,\n",
              "          3.7605e-02,  1.9010e-01, -7.3967e-02, -2.9615e-02, -3.1933e-01,\n",
              "          4.2220e-01, -3.1373e-01,  2.3636e-01, -1.0319e-01, -1.0551e-01,\n",
              "          2.2580e-01, -1.5436e-01,  1.6880e-01,  1.2399e-01, -2.6245e-01,\n",
              "          2.6504e-03,  1.8231e-01,  4.7972e-01, -4.5438e-01,  2.1366e-01,\n",
              "          2.7018e-01, -8.5801e-03, -1.7473e-01,  9.9622e-02,  1.8726e-02,\n",
              "         -2.1504e-02,  5.7803e-02, -3.2554e-02, -3.4267e-01, -1.0914e-01,\n",
              "          1.7340e-01, -5.9170e-02, -1.2866e-01,  1.1497e-01, -5.0406e-02,\n",
              "         -1.6966e-01,  5.2151e-02, -2.4521e-01, -9.3418e-02, -2.4135e-01,\n",
              "         -2.5535e-01, -4.0561e-01, -8.0384e-02, -2.2899e-01,  1.1058e-01,\n",
              "          5.2020e-02, -2.6075e-01, -2.4624e-02,  3.4294e-01, -2.3059e-01,\n",
              "         -3.1564e-01, -1.8017e-01,  1.7599e-01,  1.1806e-02,  1.6514e-01,\n",
              "         -3.0069e-02,  3.1431e-01,  7.9787e-02,  1.6114e-01, -9.3960e-02,\n",
              "          1.7455e-01, -9.0654e-02, -2.0688e-01, -1.5163e-02,  6.0626e-02,\n",
              "          3.7837e-01, -1.0811e-02, -1.1991e-01,  1.8082e-02, -4.2361e-01,\n",
              "          1.5917e-01,  1.6005e-01,  3.0407e-01,  2.1410e-02,  4.0141e-01,\n",
              "         -2.0256e-01, -4.1396e-01,  4.8155e-02, -3.5330e-01, -8.3149e-02,\n",
              "         -2.3460e-01, -9.3568e-02,  1.4875e-01,  2.8940e-02, -3.0046e-03,\n",
              "          2.1605e-01,  5.0034e-03,  3.3154e-02, -1.6652e-01,  2.2883e-02,\n",
              "         -3.2578e-02, -5.6116e-03, -4.2653e-02, -1.0969e-01,  1.4271e-01,\n",
              "         -6.5128e-02,  2.5702e-01, -1.2595e-02,  2.1722e-01,  8.5452e-01,\n",
              "          5.4104e-03, -9.2787e-02,  1.4546e-01, -1.9181e-01, -2.5597e-01,\n",
              "          2.5620e-01, -3.2100e-02,  5.4499e-01,  2.5845e-01,  1.4246e-01,\n",
              "         -1.5916e-01, -6.1155e-02,  3.9592e-02, -1.6788e-01, -1.3643e-01,\n",
              "          1.5555e-02,  1.2771e-02, -1.4615e-01,  1.1017e-01,  2.2615e-02,\n",
              "          2.2444e-01,  2.8528e-01, -1.5889e-01,  2.7188e-01,  1.1410e-01,\n",
              "          2.7186e-02, -1.7414e-01, -3.3982e-01,  3.6166e-01, -1.1872e-02,\n",
              "          3.1076e-01,  3.4573e-01,  2.7716e-02, -3.3192e-01, -3.5814e-02,\n",
              "          1.3282e-03, -1.1675e-01, -3.2956e-01,  3.5517e-02, -2.7821e-01,\n",
              "          4.5949e-01,  1.3690e-01, -1.6819e-01,  2.8072e-01, -1.8203e-01,\n",
              "          1.9335e-02, -8.8978e-01,  1.4832e-01, -1.7266e-01,  2.0721e-01,\n",
              "         -2.0563e-01,  3.3563e-01,  6.7608e-02,  1.5922e-02, -1.2866e-01,\n",
              "          2.3307e-01,  3.6974e-02, -2.9066e-01, -2.3749e-01, -2.2858e-02,\n",
              "          1.4744e-01,  2.0085e-01,  6.5990e-01,  6.7293e-02,  2.8002e-01,\n",
              "         -2.1612e-01, -1.7933e-02, -9.7879e-02, -5.4239e-01,  5.2770e-01,\n",
              "         -4.2372e-01,  3.3262e-01, -1.4226e-01,  1.0855e-01, -6.9907e-02,\n",
              "         -1.1980e-01,  3.1208e-01, -1.2939e-01, -1.0035e-01, -7.6507e-02,\n",
              "          3.0996e-01,  1.3434e-01,  1.7738e-01, -5.8535e-03, -7.8244e-02,\n",
              "          2.9957e-01,  3.7243e-01, -6.8343e-01,  4.4355e-02, -1.4177e-01,\n",
              "         -1.7623e-01, -4.7279e-01, -7.7456e+00, -8.4195e-03,  1.8206e-01,\n",
              "          1.8275e-01,  2.0138e-01,  1.7574e-01,  1.9916e-01,  7.0641e-02,\n",
              "          3.3873e-01,  6.9645e-02, -2.7848e-01, -2.2362e-01, -3.1237e-01,\n",
              "         -1.0459e-01,  2.2332e-01,  7.6265e-02, -1.3652e-01,  4.4192e-01,\n",
              "          1.4028e-01,  3.2701e-01, -7.9910e-02,  6.1681e-02,  1.7085e-01,\n",
              "         -6.5513e-02,  6.4475e-02,  2.3264e-01,  2.3646e-01,  1.7020e-02,\n",
              "          1.9108e-01, -3.1237e-01, -1.1632e-01,  3.4554e-01,  2.9212e-01,\n",
              "         -2.0002e-01,  2.2726e-01, -3.4443e-01,  3.1650e-01,  3.2343e-01,\n",
              "          1.4650e-01, -3.9564e-01, -3.2023e-02,  1.2963e-01, -1.3232e-01,\n",
              "          1.2665e-01,  2.0616e-01,  4.2218e-02, -3.9076e-02, -1.4919e-03,\n",
              "          2.5079e-01,  1.7665e-02,  1.0610e+00,  9.3263e-02,  6.6467e-06,\n",
              "         -2.8272e-01, -5.0251e-01,  3.5165e-01, -2.0473e-01,  2.6248e-01,\n",
              "          2.6459e-01,  6.4482e-02,  2.0577e-01,  3.6789e-02,  2.7710e-01,\n",
              "         -3.0890e-01, -2.4788e-01,  4.4149e-02, -5.4638e-01,  2.2138e-01,\n",
              "          1.9755e-01,  3.4288e-01, -5.5498e-01, -3.5349e-01, -3.5216e-01,\n",
              "          2.1823e-01, -5.7154e-02, -8.3381e-02, -1.4490e-01,  1.6568e-01,\n",
              "         -2.1371e-01,  2.4191e-01, -2.4694e-01,  1.5651e-01,  4.5728e-01,\n",
              "          1.2035e-01,  1.3347e-01,  5.9583e-02, -2.8405e-01,  9.4868e-02,\n",
              "         -8.8752e-02,  3.7597e-01, -8.1865e-02,  1.4495e-01,  2.8101e-01,\n",
              "          4.0558e-02,  8.5493e-02,  1.7232e-01, -1.2614e-01,  1.8729e-01,\n",
              "          1.6679e-01,  7.2911e-02, -4.0013e-02, -7.2778e-02, -1.6544e-01,\n",
              "         -1.7887e-01, -1.4143e-01,  2.1292e-02,  2.5935e-01, -2.0272e-01,\n",
              "         -1.8339e-02,  9.4128e-02,  1.6330e-01,  1.6910e-01,  2.5138e-01,\n",
              "         -1.0567e-01,  2.6862e-01, -2.1805e-02,  2.4104e-01, -2.5338e-02,\n",
              "          2.8944e-02,  3.5612e-02,  2.1818e-01,  1.6571e-01,  3.3353e-02,\n",
              "         -3.0415e-01,  1.0747e-01, -3.0288e-02, -4.6939e-02, -6.8948e-02,\n",
              "          3.2872e-01, -8.5985e-02,  4.6755e-01,  2.0828e-01, -2.5209e-01,\n",
              "         -3.3086e-01, -5.8267e-02, -2.5468e-01, -3.6369e-01,  1.3258e-01,\n",
              "         -7.9527e-01, -2.8523e-02, -6.3444e-01, -2.5385e-01,  4.2518e-01,\n",
              "          3.0383e-01,  2.1702e-01, -5.8913e-01, -2.5211e-01, -2.6222e-01,\n",
              "          2.3025e-02, -5.5774e-02, -2.2995e-01,  4.9343e-02,  3.9541e-02,\n",
              "         -4.5354e-01, -1.5128e-01, -1.7450e-01,  8.6083e-02, -2.6267e-01,\n",
              "         -2.1683e-01,  2.7210e-01, -4.2662e-03, -2.2401e-01,  2.9717e-01,\n",
              "          1.4371e-01,  7.1742e-02, -1.0496e-01, -5.2482e-02,  9.8861e-02,\n",
              "          7.2054e-03, -1.1594e-01, -8.0944e-02, -3.2756e-01,  8.2890e-02,\n",
              "          2.5257e-01, -1.4355e-01, -1.6555e-01,  2.5340e-01,  4.7978e-02,\n",
              "         -3.5500e-02,  1.2956e-01, -1.2232e-01,  1.7109e-01, -2.5120e-01,\n",
              "         -1.7110e-01,  3.3793e-01,  1.9542e-01,  1.4476e-01,  2.3747e-01,\n",
              "         -6.7673e-03,  8.7767e-02, -3.2365e-01,  1.5278e-01, -6.3044e-02,\n",
              "          2.7560e-02, -1.5361e-01,  3.9779e-01, -6.9557e-02,  2.0706e-01,\n",
              "          3.4578e-02,  2.1528e-01, -1.1222e-01, -2.9890e-02,  1.1338e-01,\n",
              "         -2.2525e-01,  5.1981e-05,  1.5335e-01, -7.7078e-02,  1.7372e-01,\n",
              "         -1.3487e-02,  2.0613e-01, -1.4131e-01]], grad_fn=<MeanBackward1>)"
            ]
          },
          "execution_count": 242,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "o[0].shape\n",
        "print(torch.mean(o[0],1).shape)\n",
        "torch.mean(o[0],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cddaeee",
      "metadata": {
        "id": "6cddaeee",
        "outputId": "7f568985-5d74-4e20-db57-4f0ae3c4cf50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.7759,  0.5508,  1.0000, -0.9964,  0.9606,  0.9481,  0.9916, -0.9851,\n",
            "         -0.9852, -0.6111,  0.9912,  0.9993, -0.9972, -0.9999,  0.7664, -0.9904,\n",
            "          0.9933, -0.6442, -1.0000, -0.6149, -0.3549, -1.0000,  0.3385,  0.9545,\n",
            "          0.9848,  0.0870,  0.9949,  1.0000,  0.8574,  0.0182,  0.3935, -0.9947,\n",
            "          0.8052, -0.9996,  0.3009, -0.0659,  0.4360, -0.4595,  0.4401, -0.8517,\n",
            "         -0.7425, -0.4531,  0.5130, -0.6632,  0.9282,  0.2589,  0.3070, -0.0266,\n",
            "         -0.1987,  1.0000, -0.9823,  0.9999, -0.9900,  0.9993,  0.9978,  0.3938,\n",
            "          0.9970,  0.2153, -0.9965,  0.4546,  0.9678,  0.1873,  0.9545, -0.3831,\n",
            "         -0.0789, -0.5588, -0.7788,  0.4396, -0.4059,  0.4095,  0.5292,  0.4842,\n",
            "          0.9940, -0.9471, -0.1695, -0.9478,  0.2050, -1.0000,  0.9759,  1.0000,\n",
            "          0.6371, -0.9999,  0.9973, -0.3195, -0.6162, -0.0515, -0.9973, -0.9998,\n",
            "          0.2102, -0.6552,  0.9261, -0.9936,  0.2623, -0.8178,  1.0000, -0.9664,\n",
            "         -0.3420,  0.4940,  0.9384, -0.4778, -0.7560,  0.8846,  0.9972, -0.9876,\n",
            "          0.9972,  0.4568, -0.9246, -0.7698,  0.6098,  0.2258,  0.9945, -0.9941,\n",
            "         -0.7012,  0.1975,  0.9480, -0.7716,  0.9947,  0.6523, -0.3749,  1.0000,\n",
            "         -0.2316,  0.9585,  0.9994,  0.7045, -0.6790, -0.3729, -0.2262,  0.8427,\n",
            "         -0.1274, -0.4314,  0.8092, -0.9935, -0.9956,  0.9998, -0.4124,  1.0000,\n",
            "         -0.9996,  0.9898, -1.0000, -0.7233, -0.7513, -0.0115, -0.9840,  0.3270,\n",
            "          0.9958,  0.1412, -0.9521, -0.7316,  0.5102, -0.7650,  0.5755,  0.8597,\n",
            "         -0.9793,  0.9997,  0.9933,  0.9332,  0.9864,  0.2926, -0.9319,  0.8740,\n",
            "          0.9942, -0.9998,  0.5371, -0.9900,  0.9997,  0.9840,  0.4263, -0.9914,\n",
            "          1.0000, -0.4062,  0.2543, -0.2063, -0.1950, -0.9972,  0.5753,  0.4857,\n",
            "          0.7521,  0.9998, -0.9975,  0.9999,  0.9946, -0.2242,  0.8220,  0.9968,\n",
            "         -0.9980, -0.9927, -0.9944,  0.5002,  0.6116,  0.4150,  0.3837,  0.9768,\n",
            "          0.9969,  0.7265, -0.9991, -0.5019,  0.9903, -0.2667,  1.0000, -0.0382,\n",
            "         -0.9999, -0.7812,  0.9375,  0.9932, -0.3824,  0.9904, -0.5831, -0.0177,\n",
            "          0.9840, -0.9997,  0.9950, -0.1185,  0.7091,  0.8957,  0.9969, -0.7249,\n",
            "         -0.2694,  0.3764, -0.5752,  1.0000, -0.9998, -0.3091,  0.5312, -0.9969,\n",
            "         -0.9992,  0.9900, -0.1121, -0.3134, -0.2885,  0.1051,  0.3195,  0.8756,\n",
            "          0.9950, -0.4770, -0.1792, -0.9999, -0.9920, -0.8878, -0.9569,  0.2377,\n",
            "          0.7401, -0.3762, -0.9453, -0.9958,  0.9813,  0.7172, -0.9317, -0.2689,\n",
            "         -0.3939, -0.9963,  0.2952, -0.7811, -0.9995,  0.9998, -0.7333,  0.9915,\n",
            "          0.9856, -0.9978,  0.7332, -0.9966, -0.0165, -0.9998,  0.2326,  0.2605,\n",
            "         -0.6933, -0.1310,  0.9967, -0.9807, -0.5668,  0.7350, -1.0000,  0.9336,\n",
            "         -0.3406,  0.9996,  0.7930,  0.0469,  0.9932,  0.9094, -0.9941, -0.9999,\n",
            "          0.8880,  0.9980, -0.9972, -0.3016,  1.0000, -0.9953, -0.8236, -0.9646,\n",
            "         -0.9977, -0.9999, -0.0360, -0.6992,  0.0599,  0.9888,  0.2745,  0.1050,\n",
            "          0.9977,  0.9990,  0.1390,  0.0472,  0.1125, -0.9864, -0.9991,  0.2899,\n",
            "          0.3213, -1.0000,  0.9999, -0.9975,  0.9998,  0.9603, -0.9845,  0.8390,\n",
            "          0.0271, -0.9606,  0.1248,  1.0000,  0.9921, -0.0739,  0.2254,  0.8955,\n",
            "         -0.0537,  0.4904, -0.7745, -0.4330,  0.2604, -0.9530,  0.9910,  0.8168,\n",
            "         -0.9967,  0.9929,  0.1894,  0.7884, -0.6431,  0.8739,  0.9949, -0.3003,\n",
            "         -0.2922, -0.1594, -0.9586, -0.9632,  0.2952, -0.9940, -0.2050,  0.8182,\n",
            "          0.9954, -0.9946,  0.9991, -0.2368,  0.9274, -0.9955,  1.0000, -0.9995,\n",
            "          0.2626,  0.5579, -0.6527, -0.4059,  0.9961,  0.9790,  0.9704, -0.8753,\n",
            "         -0.6362,  0.8862,  0.9877, -0.9765,  0.0898, -0.9980, -0.6487,  0.9982,\n",
            "          0.9908, -0.1494, -0.6294, -0.9954,  0.9790, -0.8005, -0.8412, -0.2684,\n",
            "         -0.6685,  0.2716,  0.9935, -0.2109,  0.6370,  0.2230, -0.9939,  0.8654,\n",
            "          0.6431,  0.9999, -0.9924,  0.3675,  0.9943, -0.3270, -0.6671,  0.6674,\n",
            "          0.9973, -0.9833, -0.3444, -0.9999,  0.1062, -0.7847,  0.1098, -0.2516,\n",
            "          0.1905, -0.6524,  0.9524,  0.1569,  0.8011, -0.0563,  0.9724, -0.2348,\n",
            "         -0.1275, -0.4238,  0.1597,  0.5547,  0.1357,  0.9911, -0.9820,  0.9999,\n",
            "         -0.4937, -1.0000, -0.9936, -0.7052, -0.9999,  0.3595, -0.9991,  0.9937,\n",
            "          0.9330, -0.9952, -0.9970, -0.9996, -0.9997,  0.8399,  0.4820, -0.1819,\n",
            "          0.0787,  0.9235,  0.1833,  0.0739, -0.1099, -0.9505, -0.3436, -0.9959,\n",
            "          0.5130, -1.0000, -0.6161,  0.9958, -0.9906, -0.7681, -0.9685, -0.8559,\n",
            "         -0.8662,  0.5180,  0.9925, -0.0648, -0.6477, -0.9998,  0.9944, -0.5597,\n",
            "          0.2645, -0.7625, -0.9895,  0.9999,  0.8584, -0.0851, -0.2590, -0.9997,\n",
            "          0.9792, -0.8332, -0.8754, -0.9916,  0.2593, -0.9626, -1.0000,  0.1508,\n",
            "          0.9920,  0.9992,  0.9889,  0.3547, -0.4258, -0.9687,  0.3836, -1.0000,\n",
            "          0.8430,  0.8003, -0.9888, -0.6065,  0.9952,  0.9893, -0.9461, -0.9735,\n",
            "          0.9414,  0.5634,  0.9667, -0.5593, -0.5688,  0.4252, -0.2676, -0.9956,\n",
            "         -0.9680,  0.9982, -0.9974,  0.9866,  0.9940,  0.9973,  0.0868, -0.0761,\n",
            "         -0.9842, -0.9993, -0.6589,  0.2946, -1.0000,  1.0000, -1.0000,  0.4602,\n",
            "         -0.4921,  0.7406,  0.9954, -0.2436, -1.0000, -0.9999,  0.3508, -0.1522,\n",
            "          0.9956,  0.1248,  0.3950, -0.6184, -0.0194,  0.9991, -0.7876, -0.5943,\n",
            "         -0.9964,  0.9999,  0.7049, -0.9994,  0.9931, -0.9999,  0.7896,  0.9836,\n",
            "          0.9330,  0.9854, -0.9970,  1.0000, -0.9999,  0.9994, -1.0000, -0.9974,\n",
            "          0.9999, -0.9956, -0.6915, -0.9999, -0.9952,  0.5613,  0.2600, -0.6046,\n",
            "          0.9956, -0.9999, -0.9994,  0.3505, -0.9328, -0.6916,  0.9896, -0.3470,\n",
            "          0.9970, -0.0505,  0.9731,  0.1483,  0.9934,  0.9998, -0.6777, -0.6628,\n",
            "         -0.9959,  0.9897, -0.6705,  0.4400,  0.9747,  0.0381, -0.5176,  0.5642,\n",
            "         -0.9990,  0.5752, -0.7644,  0.8905,  0.8385,  0.8684,  0.0851, -0.3463,\n",
            "         -0.0382, -0.9970,  0.6607, -0.9998,  0.9851, -0.8830,  0.1606, -0.5355,\n",
            "          0.4584, -0.9724,  0.9999,  0.9994, -0.9999,  0.1636,  0.9942, -0.4087,\n",
            "          0.9903, -0.9970, -0.1845,  0.9640, -0.7709,  0.9915,  0.2527, -0.2720,\n",
            "          0.9879, -0.9981, -0.8458, -0.7911,  0.2426,  0.1861, -0.9823,  0.2096,\n",
            "          0.9745, -0.1542, -0.9999,  0.9644, -0.9997, -0.2590,  0.9877,  0.1497,\n",
            "          1.0000, -0.6878,  0.0306,  0.0146, -0.9999, -0.9975,  0.2929, -0.2542,\n",
            "         -0.9564,  0.9979,  0.0471,  0.7463, -1.0000,  0.4326,  0.9915,  0.3845,\n",
            "          0.8600, -0.6508, -0.9608, -0.9365, -0.6367,  0.2360,  0.8298, -0.9913,\n",
            "         -0.8484, -0.7399,  1.0000, -0.9992, -0.9434, -0.9942,  0.3435,  0.8824,\n",
            "          0.5775,  0.0679, -0.8143,  0.9237, -0.8974,  0.9982, -0.9982, -0.9984,\n",
            "          0.9999,  0.4167, -0.9839, -0.0710, -0.4458,  0.2437,  0.0422,  0.6133,\n",
            "         -0.9496, -0.3010, -0.9995,  0.4712, -0.6354, -0.9951, -0.7008, -0.4545,\n",
            "         -0.9999,  0.9973,  0.9886,  1.0000, -0.9999,  0.8341,  0.2826,  0.9997,\n",
            "          0.0443, -0.7400,  0.9020,  0.9999, -0.4134,  0.5748, -0.0422, -0.1669,\n",
            "          0.2818, -0.6121,  0.9934, -0.9201,  0.3210, -0.9931, -1.0000,  1.0000,\n",
            "         -0.2319,  0.9953,  0.3359,  0.7232, -0.8915,  0.9724, -0.9816, -0.9144,\n",
            "         -1.0000,  0.2538, -0.9999, -0.9961,  0.2322,  0.9940, -0.9998, -0.9945,\n",
            "         -0.3344, -1.0000,  0.7949, -0.9815, -0.8359, -0.9935,  0.9938, -0.3451,\n",
            "         -0.0258,  0.9858, -0.9882,  0.9204,  0.9284,  0.7871,  0.3672,  0.3701,\n",
            "         -0.4471, -0.9937, -0.9279, -0.9810,  0.7499, -0.9960, -0.8928,  0.9983,\n",
            "          0.9951, -0.9997, -0.9984,  0.9924, -0.3560,  0.9933, -0.5674, -0.9999,\n",
            "         -1.0000,  0.3064, -0.2619,  0.9978, -0.4713,  0.9996,  0.7996, -0.0431,\n",
            "          0.4965, -0.4157, -0.1922, -0.2102, -0.2462,  1.0000, -0.4991,  0.9959]],\n",
            "       grad_fn=<TanhBackward>)\n"
          ]
        }
      ],
      "source": [
        "print(o[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a94a309c",
      "metadata": {
        "id": "a94a309c"
      },
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        ">>> input = torch.randn(3, 5, requires_grad=True)\n",
        ">>> target = torch.empty(3, dtype=torch.long).random_(5)\n",
        ">>> output = loss(input, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5150b935",
      "metadata": {
        "id": "5150b935",
        "outputId": "1862f4a2-9be6-4c04-ed52-ae498c86deb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 5])\n",
            "torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "print(input.shape)\n",
        "print(target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ea19567",
      "metadata": {
        "id": "0ea19567",
        "outputId": "13861328-5e3d-4ca9-86c0-3aeb90d722aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1.9612, -0.4676,  0.5422, -0.9910,  0.6087],\n",
            "        [-0.1090, -1.5409, -2.7575,  0.8405, -0.1283],\n",
            "        [ 0.6311,  1.0126, -0.9876,  0.1799,  0.0110]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c5e6a75",
      "metadata": {
        "id": "7c5e6a75",
        "outputId": "fc28bca1-7ccf-4467-d088-59e63bb63ad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2, 4, 1])\n"
          ]
        }
      ],
      "source": [
        "print(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41229814",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41229814",
        "outputId": "1d4712da-456f-41f5-b00d-8cbc2f2292b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   that    fox    sky   over    the   lazy    dog"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "from transformers import ElectraForPreTraining, ElectraTokenizerFast\n",
        "import torch\n",
        "\n",
        "discriminator = ElectraForPreTraining.from_pretrained(\"google/electra-base-discriminator\")\n",
        "tokenizer = ElectraTokenizerFast.from_pretrained(\"google/electra-base-discriminator\")\n",
        "\n",
        "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
        "fake_sentence = \"that fox sky over the lazy dog\"\n",
        "\n",
        "fake_tokens = tokenizer.tokenize(fake_sentence)\n",
        "fake_inputs = tokenizer.encode(fake_sentence, return_tensors=\"pt\")\n",
        "discriminator_outputs = discriminator(fake_inputs)\n",
        "predictions = torch.round((torch.sign(discriminator_outputs[0]) + 1) / 2)\n",
        "\n",
        "[print(\"%7s\" % token, end=\"\") for token in fake_tokens]\n",
        "\n",
        "# [print(\"%7s\" % int(prediction), end=\"\") for prediction in predictions.tolist()]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOn8R5zXhv1J",
        "outputId": "b9d6d922-c8b4-4379-b949-8be161450cd3"
      },
      "id": "iOn8R5zXhv1J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]], grad_fn=<RoundBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(discriminator_outputs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuCOiixYh-44",
        "outputId": "af5e8a95-b330-444d-d3c6-dfc845460022"
      },
      "id": "NuCOiixYh-44",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-3.2616, -4.4307,  0.0990, -1.4849, -4.9597, -4.3168, -4.6388, -2.3057,\n",
            "         -3.2615]], grad_fn=<SqueezeBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForPreTraining\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sultan/BioM-ELECTRA-Base-Discriminator\")\n",
        "\n",
        "model = AutoModelForPreTraining.from_pretrained(\"sultan/BioM-ELECTRA-Base-Discriminator\")\n",
        "\n",
        "fake_sentence = \"I will watch a movie tonight\"\n",
        "\n",
        "fake_tokens = tokenizer.tokenize(fake_sentence)\n",
        "fake_inputs = tokenizer.encode(fake_sentence, return_tensors=\"pt\")\n",
        "discriminator_outputs = discriminator(fake_inputs)\n",
        "predictions = torch.round((torch.sign(discriminator_outputs[0]) + 1) / 2)\n",
        "\n",
        "[print(\"%7s\" % token, end=\"\") for token in fake_tokens]\n",
        "\n",
        "[print(\"%7s\" % prediction, end=\"\") for prediction in predictions.tolist()]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEhKnJKyiI7P",
        "outputId": "1b77b1c3-4080-4072-93be-c0b045a05d43"
      },
      "id": "AEhKnJKyiI7P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      i   will    wat   ##ch      a    mov   ##ie    ton ##ight[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions )\n",
        "print(\"\\n\")\n",
        "discriminator_outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot-hLUA4nc5L",
        "outputId": "c2eed96d-2b9a-447f-fcd1-534f7d67923d"
      },
      "id": "Ot-hLUA4nc5L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
            "       grad_fn=<RoundBackward0>)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElectraForPreTrainingOutput([('logits',\n",
              "                              tensor([[-5.4027, -2.7329, -3.3122, -1.2622,  1.0583, -3.9619, -3.4206, -3.1851,\n",
              "                                       -4.1895, -4.0203, -4.3361]], grad_fn=<SqueezeBackward1>))])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "nrAiwcVEnkqa"
      },
      "id": "nrAiwcVEnkqa",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "BioM_electra_discriminator_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ffe97717332a4761b9b5f720106b6771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f2888043e5d94db8822a62adaafcab32",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6aec31147a864be9a24abdb9a46692e7",
              "IPY_MODEL_4ca63e30ee01445e85f808573d6e5a55",
              "IPY_MODEL_6c675789a4444a8fa2b5160d3e4322e2"
            ]
          }
        },
        "f2888043e5d94db8822a62adaafcab32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6aec31147a864be9a24abdb9a46692e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_33217b4b0a1b426cbe44c2e15880d791",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a27aa3fcfcb4908808cec9af519732a"
          }
        },
        "4ca63e30ee01445e85f808573d6e5a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_35ca3f2e3abf41fda4921aea20a9e90d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6113ca64f1e463283f3fda3a56b1572"
          }
        },
        "6c675789a4444a8fa2b5160d3e4322e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8694e51ab8964517b6423bf523e8297b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 8.62kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd41df21e20f4eaaa12bee81c3b12d92"
          }
        },
        "33217b4b0a1b426cbe44c2e15880d791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a27aa3fcfcb4908808cec9af519732a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35ca3f2e3abf41fda4921aea20a9e90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6113ca64f1e463283f3fda3a56b1572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8694e51ab8964517b6423bf523e8297b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd41df21e20f4eaaa12bee81c3b12d92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe826358e01d4fd8b97b577464b87c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e937a9233b794b69bbe320d8f125f5d8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c2a02bd28acd440c90a576850940d355",
              "IPY_MODEL_af852eb934ca4684a27d36660b53b8d7",
              "IPY_MODEL_0b7c09cec7f14b988d346e6137945b0b"
            ]
          }
        },
        "e937a9233b794b69bbe320d8f125f5d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2a02bd28acd440c90a576850940d355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_05bb6fb47d8c4cd4a7b19cd2379043ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a4ee5328eb24fda85736bd009c6729b"
          }
        },
        "af852eb934ca4684a27d36660b53b8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3fe19de71ec44e4c986614dabb773f9d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 225062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 225062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f14048b137bf4b6d8430a95544d19fee"
          }
        },
        "0b7c09cec7f14b988d346e6137945b0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_024ebd9cddd84ca7a5f648a0bd16c021",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 220k/220k [00:00&lt;00:00, 590kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4119018af8e404093c9cbede462fc4e"
          }
        },
        "05bb6fb47d8c4cd4a7b19cd2379043ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a4ee5328eb24fda85736bd009c6729b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fe19de71ec44e4c986614dabb773f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f14048b137bf4b6d8430a95544d19fee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "024ebd9cddd84ca7a5f648a0bd16c021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4119018af8e404093c9cbede462fc4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4181aaf5b2f49d9a1d9b4ac9da8d6c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9fa3d70253e4ff181e901f71378e7e1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_940afa10b5ae4ee1a80524e01e606379",
              "IPY_MODEL_bb6281863c6344feaf4021628de95b98",
              "IPY_MODEL_269d97384a504ce6aa846fb0f4dce566"
            ]
          }
        },
        "f9fa3d70253e4ff181e901f71378e7e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "940afa10b5ae4ee1a80524e01e606379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b302991ef6c248d584cbfc83ea034c9f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61588667c66045d88a64e149daa02eea"
          }
        },
        "bb6281863c6344feaf4021628de95b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ad753575b4142c4b6e8fe879ed6ab75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433021769,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433021769,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b4bdd3c4bb24d1c8d95173d142fc55b"
          }
        },
        "269d97384a504ce6aa846fb0f4dce566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_88407d80a87443eeb29e2bcc1747ddcb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 413M/413M [00:20&lt;00:00, 19.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de249909d3de490ea1c1d9357157bac3"
          }
        },
        "b302991ef6c248d584cbfc83ea034c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61588667c66045d88a64e149daa02eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ad753575b4142c4b6e8fe879ed6ab75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b4bdd3c4bb24d1c8d95173d142fc55b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88407d80a87443eeb29e2bcc1747ddcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de249909d3de490ea1c1d9357157bac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}